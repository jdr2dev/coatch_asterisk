# Orquestador LLM - Coach de Llamadas

El orquestador LLM es el componente encargado de procesar las transcripciones de las llamadas y generar consejos de coaching en tiempo real utilizando modelos de lenguaje a trav√©s de OpenRouter.

## üöÄ Instalaci√≥n y Configuraci√≥n

### Dependencias

```bash
npm i ws node-fetch dotenv
```

### Variables de Entorno

Crea un archivo `.env` con las siguientes variables:

```env
# API de OpenRouter
OPENROUTER_API_KEY=sk-or-xxxx
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet

# Configuraci√≥n del Relay
RELAY_WS=ws://127.0.0.1:7070/ws?callId=live
RELAY_EVENT=http://127.0.0.1:7070/event

# Configuraci√≥n de la aplicaci√≥n
APP_TITLE=Coach de Llamadas
STREAM=true                 # "true" para streaming SSE
TEMP=0.2                    # baja = m√°s estable
MAX_TOKENS=300              # control de coste/latencia
```

## üèÉ‚Äç‚ôÇÔ∏è Ejecuci√≥n

```bash
node orquestador-openrouter.js
```

## üîß Funcionamiento

### Flujo de Trabajo

1. **Conexi√≥n WebSocket**: Se conecta al Relay WebSocket para recibir eventos de transcripci√≥n
2. **Procesamiento**: Cuando recibe un evento `final` (transcripci√≥n completa), procesa el texto
3. **Generaci√≥n de Consejos**: Utiliza OpenRouter para generar consejos de coaching
4. **Env√≠o de Respuesta**: Env√≠a el consejo de vuelta al Relay para que llegue al frontend

### Caracter√≠sticas Principales

- **Redacci√≥n de PII**: Autom√°ticamente redacta informaci√≥n personal identificable (emails, etc.)
- **Contexto Acumulativo**: Mantiene historial de la conversaci√≥n para mejor contexto
- **Detecci√≥n de Alertas**: Identifica objeciones o riesgos y genera alertas
- **M√∫ltiples Modos**: Genera tips de conversaci√≥n, pr√≥ximas acciones y alertas
- **Manejo de Errores**: Respuestas de fallback en caso de errores del LLM

### Tipos de Respuesta

- **`tip`**: Consejos generales de conversaci√≥n (claridad, empat√≠a, descubrimiento)
- **`alert`**: Alertas cuando detecta objeciones o riesgos
- **`coach`**: Pr√≥ximas acciones sugeridas (CTA)

## üìã Configuraci√≥n del Sistema

### Modelos Soportados

- `anthropic/claude-3.5-sonnet` (recomendado)
- `openai/gpt-4o-mini`
- `meta/llama-3.1-70b-instruct`
- Otros modelos disponibles en OpenRouter

### Par√°metros de Configuraci√≥n

- **`TEMP`**: Controla la creatividad (0.1-1.0, menor = m√°s estable)
- **`MAX_TOKENS`**: Limita la longitud de respuesta (control de costos)
- **`STREAM`**: Habilita streaming para respuestas m√°s r√°pidas

## üîó Integraci√≥n

El orquestador se integra con:

- **Relay WebSocket**: Para recibir transcripciones y enviar consejos
- **OpenRouter API**: Para acceso a modelos de lenguaje
- **Sistema de Archivos**: Para logging y persistencia de historial

## üõ† Troubleshooting

### Problemas Comunes

1. **Error de conexi√≥n WebSocket**: Verificar que el Relay est√© ejecut√°ndose
2. **Error de API**: Verificar la clave de OpenRouter y l√≠mites de uso
3. **Respuestas vac√≠as**: Revisar configuraci√≥n de `MAX_TOKENS` y `TEMP`

### Logs

El orquestador registra:
- Conexiones WebSocket
- Errores de API
- Respuestas generadas
- Eventos de transcripci√≥n procesados
